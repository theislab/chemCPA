# Config for hyperparameter-tuning CPA on LINCS
seml:
  executable: compert/seml_sweep_icb.py
  name: chemical_CPA_lincs
  output_dir: sweeps/logs
  conda_environment: chemical_CPA
  project_root_dir: ..

slurm:
  max_simultaneous_jobs: 10
  experiments_per_job: 1
  sbatch_options_template: GPU
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 32G          # memory
    cpus-per-task: 6  # num cores
    # speeds is roughly 3 epochs / minute
    time: 1-00:01     # max time, D-HH:MM
###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  profiling.run_profiler: False
  profiling.outdir: "./"

  training.checkpoint_freq: 25 # checkpoint frequency to run evaluate, and maybe save checkpoint
  training.num_epochs: 1500 # maximum epochs for training. One epoch updates either autoencoder, or adversary, depending on adversary_steps.
  training.max_minutes: 1200 # maximum computation time
  training.full_eval_during_train: False
  training.run_eval_disentangle: True # whether to calc the disentanglement loss when running the full eval
  training.save_checkpoints: True # checkpoints tend to be ~250MB large for LINCS.
  training.save_dir: /storage/groups/ml01/projects/2021_chemicalCPA_leon.hetzel/sweeps/checkpoints
  
  dataset.dataset_type: lincs
  dataset.data_params.dataset_path: /storage/groups/ml01/projects/2021_chemicalCPA_leon.hetzel/datasets/lincs_full_smiles_sciplex_genes.h5ad # full path to the anndata dataset
  dataset.data_params.perturbation_key: pert_id # stores name of the drug
  dataset.data_params.pert_category: cov_drug_dose_name # stores celltype_drugname_drugdose
  dataset.data_params.dose_key: pert_dose # stores drug dose as a float
  dataset.data_params.covariate_keys: cell_id # necessary field for cell types. Fill it with a dummy variable if no celltypes present.
  dataset.data_params.smiles_key: canonical_smiles
  dataset.data_params.split_key: random_split # necessary field for train, test, ood splits.
  dataset.data_params.use_drugs_idx: True # If false, will use One-hot encoding instead

  model.load_pretrained: False
  model.pretrained_model_path: null
  model.pretrained_model_hashes: null
  model.additional_params.patience: 3 # patience for early stopping. Effective epochs: patience * checkpoint_freq.
  model.additional_params.decoder_activation: linear # last layer of the decoder
  model.additional_params.doser_type: amortized # non-linearity for doser function
  model.embedding.directory: null # null will load the path from paths.py

grid:
  model.additional_params.seed:
    type: choice
    options:
      - 1337
  model.embedding.model:
    type: choice
    options:
      - grover_base
#      - MPNN
#      - rdkit
#      - weave
#      - GCN

random:
  samples: 5
  seed: 42
  model.hparams.dropout:
    type: uniform
    min: 0.0
    max: 0.5
  model.hparams.dim:
    type: choice
    options:
      - 64
#      - 128
#      - 256
#      - 512
  model.hparams.dosers_width:
    type: choice
    options:
#      - 64
      - 128
      - 256
      - 512
  model.hparams.dosers_depth:
    type: choice
    options:
#      - 1
      - 2
      - 3
      - 4
      - 5
  model.hparams.dosers_lr:
    type: loguniform
    min: 1e-4
    max: 1e-2
  model.hparams.dosers_wd:
    type: loguniform
    min: 1e-8
    max: 1e-5
  model.hparams.autoencoder_width:
    type: choice
    options:
      - 256
      - 512
      - 1024
  model.hparams.autoencoder_depth:
    type: choice
    options:
#      - 3
#      - 4
#      - 5
      - 6
      - 7
      - 8
  model.hparams.autoencoder_lr:
    type: loguniform
    min: 1e-4
    max: 1e-2
  model.hparams.autoencoder_wd:
    type: loguniform
    min: 1e-8
    max: 1e-5
  model.hparams.adversary_width:
    type: choice
    options:
      - 64
      - 128
      - 256
  model.hparams.adversary_depth:
    type: choice
    options:
      - 2
      - 3
      - 4
      - 5
  model.hparams.adversary_lr:
    type: loguniform
    min: 5e-5
    max: 1e-3
  model.hparams.adversary_wd:
    type: loguniform
    min: 1e-5
    max: 1e-3
  model.hparams.adversary_steps: # every X steps, update the adversary INSTEAD OF the autoencoder.
    type: choice
    options:
      - 2
      - 3
  model.hparams.reg_adversary:
    type: loguniform
    min: 5
    max: 100
  model.hparams.penalty_adversary:
    type: loguniform
    min: 1
    max: 10
  model.hparams.batch_size:
    type: choice
    options:
      - 16
      - 32
      - 64
#      - 128
#      - 256
#      - 512
  model.hparams.step_size_lr:
    type: choice
    options:
      - 50
      - 100
      - 200
  model.hparams.embedding_encoder_width:
    type: choice
    options:
#      - 128
      - 256
      - 512
  model.hparams.embedding_encoder_depth:
    type: choice
    options:
#      - 2
#      - 3
      - 4
      - 5
      - 6
      - 7
